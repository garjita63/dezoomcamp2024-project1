{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5b4cde",
   "metadata": {},
   "source": [
    "## Pyspark SQL -- BigQuery (read/write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform events table into events_dwh\n",
    "# from_unixtime --> datetime (yyyy-MM-DD HH:mm:ss)\n",
    "\n",
    "project_id = \"semar-de-project1\"\n",
    "dataset_id = \"project1\"\n",
    "table_id = \"events\"\n",
    "\n",
    "df = spark.read.format('bigquery') \\\n",
    "    .option(\"temporaryGcsBucket\",\"dataproc-temp-asia-southeast2-212352110204-1oi7hped\") \\\n",
    "    .option(\"project\", project_id) \\\n",
    "    .option(\"dataset\", dataset_id) \\\n",
    "    .load(table_id)\n",
    "    \n",
    "df.createOrReplaceTempView(\"v_gcs_events\")\n",
    "\n",
    "events_transform = spark.sql(\"\"\"\n",
    "select from_unixtime((timestamp / 1000), \"yyyy-MM-dd HH:mm:ss\") as datetime, \n",
    "    visitorid, event, itemid, transactionid\n",
    "from v_gcs_events\n",
    "\"\"\")\n",
    "events_transform.show()\n",
    "\n",
    "project_id = \"semar-de-project1\"\n",
    "dataset_id = \"project1\"\n",
    "table_id = \"events_dwh\"\n",
    "\n",
    "events_transform.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"temporaryGcsBucket\",\"dataproc-temp-asia-southeast2-212352110204-1oi7hped\") \\\n",
    "    .option(\"table\", f\"{project_id}.{dataset_id}.{table_id}\") \\\n",
    "    .mode('Overwrite') \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ce5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform item_properties table into item_properties_dwh\n",
    "# from_unixtime --> datetime (yyyy-MM-DD HH:mm:ss)\n",
    "\n",
    "project_id = \"semar-de-project1\"\n",
    "dataset_id = \"project1\"\n",
    "table_id = \"item_properties\"\n",
    "\n",
    "df = spark.read.format('bigquery') \\\n",
    "    .option(\"temporaryGcsBucket\",\"dataproc-temp-asia-southeast2-212352110204-1oi7hped\") \\\n",
    "    .option(\"project\", project_id) \\\n",
    "    .option(\"dataset\", dataset_id) \\\n",
    "    .load(table_id)\n",
    "    \n",
    "df.createOrReplaceTempView(\"v_item_properties\")\n",
    "\n",
    "item_properties_transform = spark.sql(\"\"\"\n",
    "select from_unixtime((timestamp / 1000), \"yyyy-MM-dd HH:mm:ss\") as datetime, \n",
    "    itemid, property, value\n",
    "from v_item_properties\n",
    "\"\"\")\n",
    "item_properties_transform.show()\n",
    "\n",
    "project_id = \"semar-de-project1\"\n",
    "dataset_id = \"project1\"\n",
    "table_id = \"item_properties_dwh\"\n",
    "\n",
    "events_transform.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"temporaryGcsBucket\",\"dataproc-temp-asia-southeast2-212352110204-1oi7hped\") \\\n",
    "    .option(\"table\", f\"{project_id}.{dataset_id}.{table_id}\") \\\n",
    "    .mode('Overwrite') \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
